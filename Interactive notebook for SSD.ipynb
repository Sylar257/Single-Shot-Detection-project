{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-shot Detection with sgrvinod and FastAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a interactive notebook where you can change things around, experiment and singling out techniques anywhere in the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guide assume solid understand of convolutional concepts and computation. If this assumption does not hold, please feel free to check my other [repos](https://github.com/Sylar257/Image-Captioning-Project) (and [this](https://github.com/Sylar257/Skin-cancer-detection-with-stacking)) that contains more contents on these subjects.\n",
    "Hence, in this notebook, we are going to jump right into our model and explain along the way why we need all these components.<br>\n",
    "This might also be the place where you can experiment most of your modification on the archietectures. Using more powerful base-models, add in regularization layers, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from utils import *\n",
    "import torch.nn.functional as F\n",
    "from math import sqrt\n",
    "from itertools import product as product\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify GPU for cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-6-e828e45bd493>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-e828e45bd493>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    class VGGBase(nn.Module):\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class VGGBase(nn.Module):\n",
    "    # We implement VGG-16 here for low-level feature extraction\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(VGGBase, self).__init__()\n",
    "        \n",
    "        # Stabdard convolutional layers in VGG16\n",
    "        # We have an input size of 300 by 300\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)   # stride = 1, output = (300+2-3)/1+1 = 300\n",
    "        self.conv1_2 = nn.Conv2d(64,64, kernel_size=3, padding=1)   # output = 300 as before\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)          # output = (300-2)/2+1 = 150\n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # output = (150+2-3)/1+1 = 150\n",
    "        self.conv2_2 = nn.Conv2d(128,128, kernel_size=3, padding=1) # output = (150+2-3)/1+1 = 150\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)          # output = (150-2)/2 +1  = 75\n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)# output = (75+2-3)/1+1 = 75\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)# output = (75+2-3)/1+1 = 75\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)# output = (75+2-3)/1+1 = 75\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True) # ceiling (not floor) here for even dims\n",
    "        # output = ceil((75-2)/2)-1 = 38   if floor we would be getting 37 here which is an odd number\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)# output = (38+2-3)/1+1 = 38\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)# output = (38+2-3)/1+1 = 38\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)# output = (38+2-3)/1+1 = 38\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)          # output = (38-2)/2 +1  = 19\n",
    "        \n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)# output = (19+2-3)/1+1 = 19\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)# output = (19+2-3)/1+1 = 19\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)# output = (19+2-3)/1+1 = 19\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1) # We retain the size at this step with padding and stride of 1\n",
    "        # output = (19+2-3)/1+1 = 19\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
